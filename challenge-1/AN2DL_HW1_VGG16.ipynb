{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kb5A1EDL5sLN"},"source":["# UTILITIES"]},{"cell_type":"markdown","metadata":{"id":"w2PkXTog5x6T"},"source":["## SHELL OUTPUT"]},{"cell_type":"code","metadata":{"id":"OFFcmhdcicKg"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Erbjqc0p51S2"},"source":["## MODULES IMPORT"]},{"cell_type":"code","metadata":{"id":"d3iP738cyhG3"},"source":["import os\n","import tensorflow as tf\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AIwclRmr53EI"},"source":["## GOOGLE DRIVE"]},{"cell_type":"code","metadata":{"id":"0Q-gxJjjiwiX"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AVkUh8ZM57Tq"},"source":["## KAGGLE API\n","\n","Kaggle API installation. We use it for download the dataset and also upload the submission at the end."]},{"cell_type":"code","metadata":{"id":"ltlrIEUpi1mU"},"source":["!pip install -q kaggle\n","!pip install --upgrade --force-reinstall --no-deps kaggle\n","!mkdir -p ~/.kaggle\n","!cp ./drive/MyDrive/AN2DL-competitions/HW1/kaggle.json ~/.kaggle/\n","!chmod 600 /root/.kaggle/kaggle.json\n","!kaggle competitions download -c artificial-neural-networks-and-deep-learning-2020"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RPcUh4DH6P-m"},"source":["## UNZIP DATA "]},{"cell_type":"code","metadata":{"id":"4wfizGlWsSJ_"},"source":["import zipfile\n","if not os.path.exists('./MaskDataset'):\n","  with zipfile.ZipFile('./artificial-neural-networks-and-deep-learning-2020.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hr94hoVI6p1g"},"source":["# PARAMS"]},{"cell_type":"code","metadata":{"id":"wppR2tuLt0PG"},"source":["# Get current working directory\n","cwd = os.getcwd()\n","# Get Dataset directory\n","dataset_dir = os.path.join(cwd, 'MaskDataset')\n","# Image size\n","IMG_H = 256\n","IMG_W = 256\n","# Number of classes\n","NUM_CLASSES = 3\n","# Batch Size\n","BS = 32\n","# Transfer Learning\n","TL = True\n","# Learning Rate\n","LR = 1e-4\n","# Number of epochs\n","EPOCHS = 150\n","# Seed\n","SEED = 1234\n","# Early Stopping\n","ES = True\n","PATIENCE = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zwVh1umqAA7C"},"source":["# GENERATORS"]},{"cell_type":"markdown","metadata":{"id":"nY-isJe1AIJS"},"source":["## IMAGE DATA GENERATOR\n","\n","Data augmentation with all the transformations we retained correct. From \"train_data_gen\" we will obtain also the validation generator (validatio_split = 0.2)."]},{"cell_type":"code","metadata":{"id":"ZVLPBQW0tOSl"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import preprocess_input \n","\n","if TL:\n","  train_data_gen = ImageDataGenerator(zoom_range=0.1,\n","                                      horizontal_flip=True,\n","                                      rotation_range=20,\n","                                      brightness_range=[0.6, 1.4], \n","                                      fill_mode=\"nearest\",\n","                                      cval=0,\n","                                      validation_split=0.20,\n","                                      preprocessing_function=preprocess_input)\n","\n","else:\n","  train_data_gen = ImageDataGenerator(zoom_range=0.1,\n","                                      horizontal_flip=True,\n","                                      rotation_range=20,\n","                                      brightness_range=[0.6, 1.4], \n","                                      fill_mode=\"nearest\",\n","                                      cval=0,\n","                                      validation_split=0.20,\n","                                      rescale=1./255)\n","\n","test_data_gen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EDt8GKZkAL0b"},"source":["## FLOW FROM DATAFRAME\n","\n","Starting from \"train_data_gen\" this code creates \"train_gen\" and \"valid_gen\" by the use of the attributes \"subset\". For the test set, due to the fact that the images do not already have classes we used the option \"class_mode = None\"."]},{"cell_type":"code","metadata":{"id":"vvhQC0qzuyfv"},"source":["import json\n","import pandas as pd\n","from sklearn.utils import shuffle \n","\n","with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n","  dic = json.load(f)\n","\n","# we can't use only \"dic\" because the classes can't be int but strings. So this code casts them and creates the dataframe.\n","df = pd.DataFrame({k:str(v) for k, v in dic.items()}.items())\n","df.rename(columns = {0:\"filename\", 1:\"class\"}, inplace = True)\n","df = shuffle(df)\n","\n","training_dir = os.path.join(dataset_dir, 'training') \n","\n","train_gen = train_data_gen.flow_from_dataframe(dataframe=df,\n","                                               directory=training_dir,\n","                                               x_col=\"filename\",\n","                                               y_col=\"class\",\n","                                               batch_size=BS,\n","                                               target_size=(IMG_H, IMG_W),\n","                                               shuffle=True,\n","                                               class_mode='categorical',\n","                                               subset=\"training\",\n","                                               seed=SEED)\n","\n","valid_gen = train_data_gen.flow_from_dataframe(dataframe=df,\n","                                               directory=training_dir,\n","                                               x_col=\"filename\",\n","                                               y_col=\"class\",\n","                                               batch_size=BS,\n","                                               target_size=(IMG_H, IMG_W),\n","                                               shuffle=True,\n","                                               class_mode='categorical',\n","                                               subset=\"validation\",\n","                                               seed=SEED)\n","\n","test_dir = os.path.join(dataset_dir, 'test')\n","test_df = pd.DataFrame(os.listdir(test_dir))\n","test_df.rename(columns = {0:\"filename\"}, inplace = True)\n","test_gen = test_data_gen.flow_from_dataframe(dataframe=test_df,\n","                                             directory=test_dir,\n","                                             x_col=\"filename\",\n","                                             batch_size=1, \n","                                             target_size=(IMG_H, IMG_W),\n","                                             class_mode=None,\n","                                             shuffle=False,\n","                                             seed=SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxumHci2ARLm"},"source":["# MODEL"]},{"cell_type":"markdown","metadata":{"id":"G43HF6PRAWZZ"},"source":["## CALLBACKS"]},{"cell_type":"code","metadata":{"id":"MUPz6qQryO-T"},"source":["from datetime import datetime\n","\n","cwd = '/content/drive/MyDrive/AN2DL-competitions/HW1'\n","\n","experiments_dir = os.path.join(cwd, 'experiments-VGG16')\n","if not os.path.exists(experiments_dir):\n","    os.makedirs(experiments_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","model_name = 'Proj1'\n","\n","proj_dir = os.path.join(experiments_dir, model_name + '_' + str(now))\n","if not os.path.exists(proj_dir):\n","    os.makedirs(proj_dir)\n","    \n","callbacks = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0ifVzIOAekI"},"source":["### Model Checkpoint\n","\n","This code save only the best solution. With the option \"mode = max\", the best is the one with the higher validation accuracy."]},{"cell_type":"code","metadata":{"id":"ZV1JlF_IylxL"},"source":["ckpt_dir = os.path.join(proj_dir, 'checkpoints')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n","                                                   save_weights_only=True,\n","                                                   save_best_only=True,\n","                                                   mode='max') \n","callbacks.append(ckpt_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"68YQn34pAhMD"},"source":["### Tensorboard"]},{"cell_type":"code","metadata":{"id":"ourFYBaD0EGZ"},"source":["tb_dir = os.path.join(proj_dir, 'tensorboard-logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# By default shows losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVVP0cruAkAJ"},"source":["### Early Stopping"]},{"cell_type":"code","metadata":{"id":"v20t8vff0GBr"},"source":["if ES:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3eEoQKqAnPl"},"source":["## DEFINITION"]},{"cell_type":"markdown","metadata":{"id":"ceQte_l5Atml"},"source":["### Transfer learning"]},{"cell_type":"code","metadata":{"id":"Vqf7kWOyw7wz"},"source":["if TL:\n","  vgg = tf.keras.applications.VGG16(weights='imagenet', \n","                                           include_top=False, \n","                                           input_shape=(IMG_H, IMG_W, 3))\n","  \n","vgg.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JT0A9qBw7zW"},"source":["# this select how many layers to freeze\n","\n","if TL:\n","\n","  finetuning = True\n","  all_trainable = False\n","\n","  if all_trainable:\n","    vgg.trainable = True\n","  elif finetuning:\n","    freeze_until = 15\n","    for layer in vgg.layers[:freeze_until]:\n","          layer.trainable = False\n","  else:\n","    vgg.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d93mwIYD08Sa"},"source":["# we used the following list for create a file with the main \n","# parameteres of the NN (see later \"params description\") \n","neurons_per_layer = []\n","neurons_per_layer.append(128)\n","neurons_per_layer.append(128)\n","\n","\n","model = tf.keras.Sequential()\n","model.add(vgg)\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=neurons_per_layer[0], activation='relu'))\n","model.add(tf.keras.layers.Dense(units=neurons_per_layer[1], activation='relu'))\n","\n","model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1MStAm5-AwYv"},"source":["### Custom model"]},{"cell_type":"code","metadata":{"id":"60jrfWwTxu5W"},"source":["if not TL:\n","  \n","  start_f = 8\n","  depth = 5\n","\n","  model = tf.keras.Sequential()\n","\n","  # Features extraction\n","  for i in range(depth):\n","\n","    if i == 0:\n","        input_shape = [IMG_H, IMG_W, 3]\n","    else:\n","        input_shape=[None]\n","\n","    # Conv block: Conv2D -> Activation -> Pooling\n","    model.add(tf.keras.layers.Conv2D(filters=start_f, \n","                                     kernel_size=(3, 3),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     input_shape=input_shape))\n","    model.add(tf.keras.layers.ReLU())\n","    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","    start_f *= 2\n","      \n","  # Classifier\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n","  model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax'))\n","\n","  model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o3HexvdeATcD"},"source":["## OPTIMIZATION PARAMS"]},{"cell_type":"code","metadata":{"id":"MMVPidm3x191"},"source":["# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# Optimizer\n","optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n","\n","# Metrics\n","metrics = ['accuracy']\n","\n","# Set random seed\n","tf.random.set_seed(SEED)\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j3EsULg1A3UY"},"source":["# TRAINING"]},{"cell_type":"markdown","metadata":{"id":"5ODAp_XGA7fx"},"source":["## PARAMS DESCRIPTION\n","\n","This code creates a file in the actual project folder for remebering us the main parameters of the NN. In this way we could immediately distinguish one experiment from the others."]},{"cell_type":"code","metadata":{"id":"0MR22ykt64Mg"},"source":["f = open(os.path.join(proj_dir, \"params.txt\"), \"w+\")\n","f.write('IMG = ' + str(IMG_H) + ' x ' + str(IMG_H) + '\\n')\n","f.write('BS = ' + str(BS) + '\\n')\n","f.write('LR = ' + str(LR) + '\\n')\n","f.write('EPOCHS = ' + str(EPOCHS) + '\\n')\n","f.write('SEED = ' + str(SEED) + '\\n')\n","f.write('ES = ' + str(ES))\n","if ES:\n","  f.write(' with PETIENCE = ' + str(PATIENCE) + '\\n')\n","else:\n","  f.write('\\n')\n","f.write('TL (VGG) = ' + str(TL) + '\\n')\n","if finetuning and not all_trainable:\n","  f.write('FT = ' + str(finetuning) + ' with weights freezed until ' + str(freeze_until) + '\\n')\n","elif all_trainable:\n","  f.write('All trainable\\n')\n","for i in range(len(neurons_per_layer)):\n","  f.write('Layer ' + str(i) + ' with ' + str(neurons_per_layer[i]) + ' units\\n')\n","for i in range(len(dropout_per_layer)):\n","  f.write('Layer ' + str(i) + ' with DROPOUT = ' + str(dropout_per_layer[i]) + ' \\n')\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTBet1ywA_hF"},"source":["## TENSORBOARD"]},{"cell_type":"code","metadata":{"id":"tfTOkrOj0qKV"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/AN2DL-competitions/HW1/experiments-VGG16/ --port 6009"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2B0-riKJBCjA"},"source":["## FIT METHOD"]},{"cell_type":"code","metadata":{"id":"uZBVeBAE0q9d"},"source":["model.fit(train_gen,\n","          epochs=EPOCHS,\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_gen,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_5jZFnKBGeL"},"source":["# CSV FOR SUBMISSION"]},{"cell_type":"markdown","metadata":{"id":"V4rtlOT5BK8g"},"source":["## MODEL RE-DEFINITION"]},{"cell_type":"code","metadata":{"id":"tm6RT6v01E1e"},"source":["del model\n","\n","neurons_per_layer = []\n","neurons_per_layer.append(128)\n","neurons_per_layer.append(128)\n","\n","\n","model = tf.keras.Sequential()\n","model.add(vgg)\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=neurons_per_layer[0], activation='relu'))\n","model.add(tf.keras.layers.Dense(units=neurons_per_layer[1], activation='relu'))\n","\n","model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oG6uYil82JDp"},"source":["model.load_weights(tf.train.latest_checkpoint(ckpt_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F7yCm3R6BM_6"},"source":["## CSV FUNCTION"]},{"cell_type":"code","metadata":{"id":"A5nCYPi32TtT"},"source":["def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'results.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACw8OZiUBQ9A"},"source":["## RESULTS & SUBMISSION\n","\n","Exploiting the previous function this code creates the CSV file and submits it on Kaggle."]},{"cell_type":"code","metadata":{"id":"a2j2NwiR2foX"},"source":["predicted_class = tf.argmax(model.predict(test_gen), 1)\n","\n","i=0\n","results={}\n","images_name = os.listdir(test_dir)\n","images_name.sort()\n","\n","for f in images_name:\n","  results[f] =  predicted_class.numpy().tolist()[i]\n","  i+=1\n","\n","create_csv(results)\n","\n","!kaggle competitions submit -c artificial-neural-networks-and-deep-learning-2020 -f ./results.csv -m \"Submission\""],"execution_count":null,"outputs":[]}]}